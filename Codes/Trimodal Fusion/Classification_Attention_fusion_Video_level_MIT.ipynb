{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Import Packages**"
      ],
      "metadata": {
        "id": "gUiRKoRPY1-l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qpbo-y6lTMYt"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import linear_model\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn import metrics\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.decomposition import PCA\n",
        "import scipy.io as sio\n",
        "import matplotlib as mpl\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import merge\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn import preprocessing\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, concatenate,multiply\n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
        "from keras.layers import Lambda\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Add\n",
        "from keras.layers import LayerNormalization\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification Methods**\n",
        "\n",
        "Label Discretization and Majority Voting\n"
      ],
      "metadata": {
        "id": "kkGzqjrSZFa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#function to convert continous labels into binary labels\n",
        "def bin_labels(data_rec):             \n",
        "    count_0 = 0\n",
        "    count_1 = 0\n",
        "    median_value = np.median(data_rec)\n",
        "    print(\"Inside bin labels function: \" + str(median_value))\n",
        "    for it in range(0,len(data_rec),1):\n",
        "        if data_rec[it]<=median_value :\n",
        "            count_0 += 1\n",
        "            data_rec[it]=0\n",
        "        else:\n",
        "            count_1 += 1\n",
        "            data_rec[it]=1\n",
        "    print(count_0, count_1)\n",
        "    return data_rec\n",
        "def find_median(data_rec):\n",
        "    median_value = np.median(data_rec)\n",
        "    print(\"Inside med function: \" + str(median_value))\n",
        "    return median_value\n",
        "\n",
        "#function to convert continous labels into binary labels for the test set based on the median from train data\n",
        "def bin_labels_test(data_rec, train_median):             \n",
        "    count_0 = 0\n",
        "    count_1 = 0\n",
        "    # median_value = train_median\n",
        "    for it in range(0,len(data_rec),1):\n",
        "        if data_rec[it]<=train_median :\n",
        "            count_0 += 1\n",
        "            data_rec[it]=0\n",
        "        else:\n",
        "            count_1 += 1\n",
        "            data_rec[it]=1\n",
        "    print(count_0, count_1)\n",
        "    return data_rec \n",
        "\n",
        "\n",
        "#function to return the majority from a list of labels\n",
        "def majority_vote(arr):\n",
        "    vote_count = Counter(arr)\n",
        "    top_two = vote_count.most_common(2)\n",
        "    if len(top_two)>1 and top_two[0][1] == top_two[1][1]:\n",
        "        # It is a tie\n",
        "        return 0\n",
        "    return top_two[0][0]\n",
        "\n"
      ],
      "metadata": {
        "id": "tlqvFZ-uZI-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Kineme Feature Chunks**"
      ],
      "metadata": {
        "id": "S9ZeQ4TlZr23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# onehot encoding of kineme sequence\n",
        "def onehot_encoding(ks, nKineme):\n",
        "    #print(ks)\n",
        "    onehot_encoded = list()\n",
        "    for k in ks:\n",
        "        vec = [0 for _ in range(nKineme)]\n",
        "        vec[k-1] = 1\n",
        "        onehot_encoded.append(vec)\n",
        "    return onehot_encoded\n",
        "\n",
        "\n",
        "\n",
        "def ks_encoding(ks, nKineme):\n",
        "    # ks is a numpy ndarray\n",
        "    m, n = ks.shape #m=92, n=29\n",
        "    #print(m, n)\n",
        "    ks = ks.tolist() #converted to list\n",
        "    encoded_features = np.asarray(\n",
        "        [np.asarray(onehot_encoding(ks[i], nKineme)) for i in range(m)]\n",
        "    )\n",
        "    return encoded_features\n",
        "\n",
        "def data_preprocess(chunk_time, input_file_kineme, label_val, num_chunk): \n",
        "    data_list = []\n",
        "    total_num_chunks = 0\n",
        "    label_file_index = 0\n",
        "    final_label = [] \n",
        "    final_data_file = input_file_kineme.T     \n",
        "    for num in range(0, num_chunk):\n",
        "        data_chunk = final_data_file[num*(chunk_time-1):((num+1)*(chunk_time-1))]\n",
        "        # print(\"Chunks dim in kineme \" + str(num*(chunk_time-1)) + \" \"+ str(((num+1)*(chunk_time-1))))\n",
        "        data_chunk = data_chunk.to_numpy()\n",
        "        data_list.append(data_chunk.flatten())\n",
        "    one_list = label_val.repeat(num_chunk)\n",
        "    final_label.extend(one_list)                 \n",
        "    return  data_list, final_label\n",
        "\n",
        "#Function to create kineme data matrix for Test Data\n",
        "def data_preprocess_test(chunk_time, input_file_kineme, num_chunk): \n",
        "    data_list = []\n",
        "    total_num_chunks = 0\n",
        "    label_file_index = 0\n",
        "    final_label = []\n",
        "    final_data_file = input_file_kineme.T \n",
        "    for num in range(0, num_chunk):\n",
        "        data_chunk = final_data_file[num*(chunk_time-1):((num+1)*(chunk_time-1))]\n",
        "        data_chunk = data_chunk.to_numpy()\n",
        "        data_list.append(data_chunk.flatten())              \n",
        "    return  data_list"
      ],
      "metadata": {
        "id": "X9vuBSmBZqUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating AU (Action Units) Feature Chunks**"
      ],
      "metadata": {
        "id": "c7sVux9mZsSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def max_encoding(input_file_au,threshold,chunk_size,total_chunks):\n",
        "    # print(\"AU chunks\")\n",
        "    count = 0\n",
        "    duration = 0\n",
        "    overlap = 10\n",
        "    complete_vec = []\n",
        "    intensity_var = threshold  \n",
        "    read_data = np.array(input_file_au) \n",
        "    for c in range(0,total_chunks,1):           #total_chunks= 10 , c= 0 \n",
        "        vector = []\n",
        "        for j in range(0, chunk_size-1, 1): #0 1 2 0 20 10 30 20 40\n",
        "            # print(\"Chunkk number for this file \" + str(j))\n",
        "            # print(\"chunk dim \"+ str(duration) + \" \"+ str(duration+20))\n",
        "            max_pool = [] \n",
        "            for i in range(5, 22, 1):\n",
        "                max_value = np.max(read_data[duration:duration+20, i])\n",
        "                if max_value <= intensity_var:\n",
        "                    max_value = 0\n",
        "                else:\n",
        "                    max_value = 1\n",
        "                max_pool.append(max_value)\n",
        "            duration = duration + overlap\n",
        "            vector.append(max_pool)\n",
        "        vec_flat = np.array(vector).flatten()\n",
        "        complete_vec.append(vec_flat)\n",
        "    return complete_vec\n"
      ],
      "metadata": {
        "id": "UYqUrNgmZkYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Audio Feature Chunks**"
      ],
      "metadata": {
        "id": "wYCAVKBKZstm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chunks_formation(f, chunk_time, size_of_feature_set,num_chunks):\n",
        "    # print(\"Audio chunks\")\n",
        "    data_list = []\n",
        "    csv_file   = pd.read_csv(f, header=None)\n",
        "    i = 0          \n",
        "    entire_file_mat = []     \n",
        "    while i < csv_file.shape[1]:\n",
        "        new_frame = csv_file.loc[:, i:i+87]\n",
        "        # print(\"Frame dimension \"+ str(i) + \" \" + str(i+87))\n",
        "        i = i + 44\n",
        "        avg_value = new_frame.mean(axis=1)\n",
        "        file_mat = pd.concat([avg_value], axis=1, ignore_index=True)\n",
        "        file_mat = file_mat.to_numpy().flatten()\n",
        "        file_mat = pd.DataFrame(file_mat)\n",
        "        entire_file_mat = np.concatenate((entire_file_mat, file_mat), axis=None)\n",
        "        new_array = entire_file_mat\n",
        "        value_to_be_minus = new_array.shape[0]-(2*size_of_feature_set)\n",
        "        new_array = new_array[0:value_to_be_minus] #To handle extra 2 sec data\n",
        "    for num in range(0, num_chunks):\n",
        "        data_chunk = new_array[num*(chunk_time-1)*size_of_feature_set:((num+1)*(chunk_time-1)*size_of_feature_set)]\n",
        "        data_list.append(data_chunk)  \n",
        "    data_array = np.array(data_list) \n",
        "    my_df = pd.DataFrame(data_array)\n",
        "    Data = my_df.fillna(method='ffill')\n",
        "    Data = Data.fillna(method='bfill')\n",
        "    Data = np.asarray(Data)\n",
        "    return Data\n",
        "\n",
        "def chunks_formation_test(file_path, chunk_time, size_of_feature_set,scaler,num_chunks):\n",
        "    f = file_path\n",
        "    data_list = []\n",
        "    csv_file   = pd.read_csv(f, header=None)\n",
        "    i = 0          \n",
        "    entire_file_mat = []\n",
        "    while i < csv_file.shape[1]:\n",
        "        new_frame = csv_file.loc[:, i:i+87]\n",
        "        i = i + 44\n",
        "        avg_value = new_frame.mean(axis=1)\n",
        "        file_mat = pd.concat([avg_value], axis=1, ignore_index=True)\n",
        "        file_mat = file_mat.to_numpy().flatten()\n",
        "        file_mat = pd.DataFrame(file_mat)\n",
        "        entire_file_mat = np.concatenate((entire_file_mat, file_mat), axis=None)\n",
        "        new_array = entire_file_mat\n",
        "        value_to_be_minus = new_array.shape[0]-(2*size_of_feature_set)\n",
        "        new_array = new_array[0:value_to_be_minus] #To handle extra 2 sec data\n",
        "    for num in range(0, num_chunks):\n",
        "        data_chunk = entire_file_mat[num*(chunk_time-1)*size_of_feature_set:((num+1)*(chunk_time-1)*size_of_feature_set)]\n",
        "        data_list.append(data_chunk)\n",
        "    data_array = np.asarray(data_list)\n",
        "    data_df= pd.DataFrame(data_array)\n",
        "    Data = data_df.fillna(method='ffill')\n",
        "    Data = Data.fillna(method='bfill')\n",
        "    Data = np.asarray(Data)\n",
        "    scaled_Data = scaler.transform(Data)\n",
        "    Data_final = scaled_Data\n",
        "    return Data_final"
      ],
      "metadata": {
        "id": "HAFWfFu6Zc-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attention Fusion Model**"
      ],
      "metadata": {
        "id": "Vt_fwmb6Ztzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "nNeuron = 12\n",
        "chunk_size = 10\n",
        "label_name = 'EyeContact'\n",
        "seqLen = chunk_size-1\n",
        "nKineme, nClass = 16, 1\n",
        "nAction, nAudio = 17, 23\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 32\n",
        "threshold_action_units = 1.5\n",
        "\n",
        "def split_tensor(X):\n",
        "  s0, s1, s2 = tf.split(X, num_or_size_splits=3,axis = -1)\n",
        "  return s0,s1,s2\n",
        "\n",
        "def mul1(x):\n",
        "  soft = x\n",
        "  with tf.compat.v1.Session() as sess:\n",
        "    T_onehot = tf.one_hot(tf.argmax(soft, 1), soft.shape[1])\n",
        "  return T_onehot\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "#left input LSTM\n",
        "kineme_branch_input = Input(shape=(seqLen, nKineme), name=\"kineme_input\")\n",
        "kineme_branch_output = LSTM(nNeuron, activation = 'tanh', name=\"kineme_dense\")(kineme_branch_input)\n",
        "kineme_branch_norm = LayerNormalization( name = \"kineme_normal\")(kineme_branch_output)\n",
        "#middle branch input\n",
        "au_branch_input = Input(shape=(seqLen, nAction), name='action_input')\n",
        "au_branch_output = LSTM(nNeuron, activation = 'tanh', name=\"action_dense\")(au_branch_input)\n",
        "au_branch_norm = LayerNormalization(name = \"action_normal\")(au_branch_output)\n",
        "#right input LSTM\n",
        "audio_branch_input = Input(shape=(seqLen, nAudio), name='audio_input')\n",
        "audio_branch_output = LSTM(nNeuron, activation = 'tanh', name='audio_dense')(audio_branch_input)\n",
        "audio_branch_norm = LayerNormalization(name = \"audio_normal\")(audio_branch_output)\n",
        "#Merged Layer and calculating softmax score from the dense layer of the actual real embeddings \n",
        "merge_layer = concatenate([kineme_branch_output, au_branch_output, audio_branch_output], name='Concatenate_modalities')\n",
        "merge_dense = Dense(nNeuron, activation='tanh', name='concatenate_dense')(merge_layer)\n",
        "softmax_output = Dense(3, activation='softmax', name='softmax_score')(merge_dense)\n",
        "\n",
        "kineme_val, au_val, audio_val = Lambda(split_tensor)(softmax_output)\n",
        "\n",
        "score_kin_mul = multiply([kineme_branch_norm, kineme_val], name='Concatenate_score_mul_k')\n",
        "score_au_mul = multiply([au_branch_norm, au_val], name='Concatenate_score_mul_au')\n",
        "score_audio_mul = multiply([audio_branch_norm, audio_val], name='Concatenate_score_mul_aud')\n",
        "\n",
        "#for concatenate attention\n",
        "addition_layer = Add()([score_kin_mul, score_au_mul, score_audio_mul])\n",
        "final_model_output = Dense(nClass, activation='sigmoid')(addition_layer)\n",
        "final_model = Model(inputs=[kineme_branch_input, au_branch_input, audio_branch_input], outputs=final_model_output,name='Final_output')\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "final_model.compile(optimizer = opt, loss = 'binary_crossentropy',metrics=['accuracy'])\n",
        "final_model.summary()"
      ],
      "metadata": {
        "id": "hVICYHYfZT8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Files**"
      ],
      "metadata": {
        "id": "nxS4cmCdZu2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#path to all the kineme files\n",
        "file_list = sorted(glob.glob('/content/drive/MyDrive/Research_Related/Ongoing_Research/Kineme_Project/Kineme_Files/MIT/VL/AU_10fps/*.csv'))\n",
        "label_data = pd.read_csv('/content/drive/MyDrive/Research_Related/Ongoing_Research/Kineme_Project/Kineme_Files/MIT/VL/labels_traits_minmax_norm.csv')\n",
        "label = label_data[label_name]\n",
        "f = np.array(file_list).reshape(-1,1) #All data files\n",
        "label = pd.to_numeric(label, downcast='integer') #Float to integer conversion\n",
        "label = label.to_numpy().reshape(-1,1)  \n",
        "file_to_work = np.concatenate((f, label),axis=1)   #File plus label in single array\n",
        "\n",
        "test_loss=[]\n",
        "test_acc=[]\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "fi_weighted=[]\n",
        "fi_macro=[]\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "inter_output_train = np.zeros((1,3))\n",
        "inter_output_test = np.zeros((1,3))\n",
        "list_file_test_set = []\n",
        "# print(inter_output_test)\n"
      ],
      "metadata": {
        "id": "mX2tAjw-ZP3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train and Test**"
      ],
      "metadata": {
        "id": "pTdGov3mZvr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 1\n",
        "random_state = 42\n",
        "rkf = RepeatedKFold(n_splits=10, n_repeats=5, random_state=random_state)      #repeat kfold function\n",
        "for train_idx, test_idx in rkf.split(file_to_work):\n",
        "    print(\"@@@@@@@@ On the iteration \" + str(count) + \" @@@@@@@@\")\n",
        "    train_features, test_features = file_to_work[train_idx], file_to_work[test_idx]\n",
        "    file_path = train_features[:,0].tolist()  #File list for chunk preparation\n",
        "    labels = train_features[:,1]  #labels for chunk preparation\n",
        "    file_name = Path(file_path[0]).stem \n",
        "    #paths for files\n",
        "    outer_directory  = '/content/drive/MyDrive/Research_Related/Ongoing_Research/Kineme_Project/Kineme_Files/MIT/VL'\n",
        "    AU_path = outer_directory + '/AU_10fps/' + file_name + '.csv'\n",
        "    Kine_Path = outer_directory + '/Kinemes/' + file_name + '.csv'\n",
        "    Audio_path = outer_directory + '/MIT_Data_CSV/' + file_name +'_audio.csv'\n",
        "    #creation of data frames with the initial csv paths of kineme and AU and label; \n",
        "    AU1 = pd.read_csv(AU_path)\n",
        "    Kin1 = pd.read_csv(Kine_Path, header=None)\n",
        "    label = labels[0]\n",
        "    chun_au = int(AU1.shape[0]/((chunk_size)*10))\n",
        "    chun_ki = int(Kin1.shape[1]/(chunk_size))\n",
        "    if chun_au <= chun_ki:\n",
        "        total_size = chun_au\n",
        "    else:\n",
        "        total_size = chun_ki\n",
        "    kin_res1,label1 = data_preprocess(chunk_size,Kin1,label,total_size)\n",
        "    au_res1 = max_encoding(AU1,threshold_action_units,chunk_size,total_size)\n",
        "    audio_res1 = chunks_formation(Audio_path, chunk_size, nAudio,total_size)\n",
        "    kin_res1 = np.array(kin_res1)\n",
        "    au_res1 = np.array(au_res1)\n",
        "    for i in range(0,len(file_path)-1,1):\n",
        "        file_name = Path(file_path[i+1]).stem   \n",
        "        AU_path = outer_directory + '/AU_10fps/' + file_name + '.csv'\n",
        "        Kine_Path = outer_directory + '/Kinemes/' + file_name + '.csv'\n",
        "        Audio_path = outer_directory + '/MIT_Data_CSV/' + file_name +'_audio.csv'\n",
        "        AU2 = pd.read_csv(AU_path)\n",
        "        Kin2 = pd.read_csv(Kine_Path, header=None)\n",
        "        label2 = labels[i+1]\n",
        "        chun_au = int(AU2.shape[0]/(chunk_size*10))\n",
        "        chun_ki = int(Kin2.shape[1]/(chunk_size))\n",
        "        if chun_au<=chun_ki:\n",
        "            total_size = chun_au\n",
        "        else:\n",
        "            total_size = chun_ki\n",
        "        kin_res2,label2 = data_preprocess(chunk_size,Kin2,label2,total_size)\n",
        "        au_res2 = max_encoding(AU2,1.5,chunk_size,total_size)\n",
        "        audio_res2 = chunks_formation(Audio_path, chunk_size, 23,total_size)\n",
        "        #make array of results\n",
        "        kin_res2 = np.array(kin_res2)\n",
        "        au_res2 = np.array(au_res2)\n",
        "        #Matrix merging\n",
        "        kin_res1 = np.vstack((kin_res1,kin_res2))\n",
        "        au_res1 = np.vstack((au_res1,au_res2))\n",
        "        audio_res1 = np.vstack((audio_res1,audio_res2))\n",
        "        label1.extend(label2)\n",
        "        # print(file_name, total_size)\n",
        "\n",
        "    final = np.concatenate((kin_res1.T, au_res1.T)).T\n",
        "    scaler = preprocessing.StandardScaler().fit(audio_res1)\n",
        "    final_audio = scaler.transform(audio_res1)\n",
        "    final_label = np.array(label1)\n",
        "    final_label = [float(i) for i in final_label]   #String to float conversion\n",
        "    train_median = find_median(final_label)\n",
        "    final_label = bin_labels(final_label)\n",
        "    train_labels = np.array(final_label)\n",
        "    train_kinemes = ks_encoding(final[:,0:seqLen], nKineme)\n",
        "    train_action = final[:, seqLen:]\n",
        "    train_action = train_action.reshape((train_action.shape[0], seqLen, nAction))\n",
        "    train_audio = final_audio.reshape((final_audio.shape[0], seqLen, nAudio))\n",
        "    zero_bias_history = final_model.fit([train_kinemes, train_action, train_audio], train_labels, epochs = EPOCHS, batch_size = 32, validation_split=0.1, callbacks=[callback])  #Fitting the model \n",
        "    print(\"Model Training is Done\")\n",
        "\n",
        "    #Process for testing\n",
        "    test_data = test_features[:,0].tolist()  #test data\n",
        "    test_labels = test_features[:,1]  #test actual label\n",
        "    test_labels = [float(i) for i in test_labels]   #String to int conversion\n",
        "    test_labels = bin_labels_test(test_labels, train_median)\n",
        "    y_pred_video = []\n",
        "    \n",
        "    for i in range(0,len(test_data)):\n",
        "        file_name = Path(test_data[i]).stem   \n",
        "        AU_path = outer_directory + '/AU_10fps/' + file_name + '.csv'\n",
        "        Kine_Path = outer_directory + '/Kinemes/' + file_name + '.csv'\n",
        "        Audio_path = outer_directory + '/MIT_Data_CSV/' + file_name +'_audio.csv'\n",
        "\n",
        "        AU2 = pd.read_csv(AU_path)\n",
        "        Kin2 = pd.read_csv(Kine_Path, header=None)\n",
        "        chun_au = int(AU2.shape[0]/((chunk_size)*10))\n",
        "        chun_ki = int(Kin2.shape[1]/(chunk_size))\n",
        "        if chun_au <= chun_ki:\n",
        "            total_size = chun_au\n",
        "        else:\n",
        "            total_size = chun_ki\n",
        "        kin_res2 = data_preprocess_test(chunk_size,Kin2,total_size)\n",
        "        au_res2 = max_encoding(AU2,1.5,chunk_size,total_size)\n",
        "        audio_res2 = chunks_formation_test(Audio_path, chunk_size, 23,scaler,total_size)\n",
        "\n",
        "        #make array of results\n",
        "        kin_res2 = np.array(kin_res2)\n",
        "        au_res2 = np.array(au_res2)\n",
        "        final_test = np.concatenate((kin_res2.T, au_res2.T)).T\n",
        "        \n",
        "        test_kinemes = ks_encoding(final_test[:,0:seqLen], nKineme)\n",
        "        test_action = final_test[:, seqLen:]\n",
        "        test_action = test_action.reshape((test_action.shape[0], seqLen, nAction))\n",
        "        test_audio = audio_res2.reshape((audio_res2.shape[0], seqLen, nAudio))\n",
        "        y_pred = final_model.predict([test_kinemes, test_action, test_audio])\n",
        "        y_pred = ((y_pred >= 0.5)+0).ravel()\n",
        "        y1 = majority_vote(y_pred)   #Voting for classification to change\n",
        "        y_pred_video.append(y1)\n",
        "        print(\"----------Files in test set\")\n",
        "        print(file_name, total_size)\n",
        "        list_file_test_set.extend([file_name, total_size])\n",
        "        intermediate_model_folds= Model(inputs=final_model.input ,outputs=final_model.get_layer(index = 8).output)\n",
        "        inter_output_fold_test = intermediate_model_folds.predict([test_kinemes, test_action, test_audio])\n",
        "        inter_output_fold_test = np.asarray(inter_output_fold_test)\n",
        "        inter_output_test = np.row_stack((inter_output_test, inter_output_fold_test))\n",
        "    acc_val = accuracy_score(test_labels, y_pred_video)\n",
        "    test_acc.append(acc_val)\n",
        "    print('Test accuracy:', acc_val)   \n",
        "    train_acc.append(np.array(zero_bias_history.history['accuracy']).mean()) \n",
        "    val_acc.append(np.array(zero_bias_history.history['val_accuracy']).mean()) \n",
        "    f1_w_epoch = f1_score(test_labels, y_pred_video, average='weighted')\n",
        "    f1_m_epoch = f1_score(test_labels, y_pred_video, average='macro')\n",
        "    fi_weighted.append(f1_w_epoch)\n",
        "    fi_macro.append(f1_m_epoch)"
      ],
      "metadata": {
        "id": "khidWPMmZOrj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
